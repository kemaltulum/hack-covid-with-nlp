{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweet Collection and Storing Them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Insert tweets into db with some id, hashing its text and user\n",
    "\n",
    "\n",
    "### FoxTV Ana Haber Bülteni Hashtag'leri\n",
    "\n",
    "* 2 Nisan 2020 : #şüpheduymuyorum\n",
    "* 3 Nisan 2020 : #duysesimi\n",
    "* 4 Nisan 2020 : #\n",
    "* 5 Nisan 2020 : #\n",
    "* 6 Nisan 2020 : #neyinnesi (Erdoğan Açıklama 19:00)\n",
    "* 7 Nisan 2020 : #biralkışda\n",
    "* 8 Nisan 2020 : #hepsinitopla\n",
    "* 9 Nisan 2020 : #kabuledilemez\n",
    "* 10 Nisan 2020 : #neredenbulacağım"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import BulkWriteError\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "db = client.covid_hack\n",
    "tweets_db = db.tweets\n",
    "\n",
    "tweets_db.find_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('keys.json')\n",
    "key_dict = json.loads(file.read())\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(key_dict['consumer_key'], key_dict['consumer_secret'])\n",
    "auth.set_access_token(key_dict['access_token'], key_dict['access_token_secret'])\n",
    "\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tweet(tweet, hashtag_id):\n",
    "    tweet['hashtag_id'] = hashtag_id\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "searched_hashtags = ['#şüpheduymuyorum', '#duysesimi', '#biralkısda', '#neyinnesi', \"#biralkışda\", '#hepsinitopla']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_search_continue = True\n",
    "check_all_for_dup = True\n",
    "hashtag_id = '#gerçekfikrine'\n",
    "max_id = None\n",
    "request_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open('conflicts.txt', 'a+')\n",
    "\n",
    "while tweet_search_continue:\n",
    "    \n",
    "    print(\"Request {}\".format(request_number))\n",
    "    \n",
    "    request_number += 1\n",
    "    \n",
    "    tweets = api.search(q=hashtag_id, count=100, lang=\"tr\", max_id=max_id, tweet_mode=\"extended\")\n",
    "    \n",
    "    if len(tweets) == 0:\n",
    "        print(\"No tweets fetched\")\n",
    "        break\n",
    "    \n",
    "    tweets = [tweet._json for tweet in tweets]\n",
    "\n",
    "    print(\"Number of tweets {}\".format(len(tweets)))\n",
    "    \n",
    "    tweets_filtered = []\n",
    "    for tweet in tweets:\n",
    "        \n",
    "        # Check if it is a RT, if RT do no include\n",
    "        if tweet['full_text'].startswith('RT'):\n",
    "            continue\n",
    "        \n",
    "        no_conflict = True\n",
    "        \n",
    "        for hashtag in searched_hashtags:\n",
    "            if hashtag in tweet['full_text']:\n",
    "                print(\"Hashtag {} found in tweet {}\".format(hashtag, tweet['id']))\n",
    "                found = tweets_db.find_one({'id': tweet['id']})\n",
    "                if found:\n",
    "                    print(\"{}:{}:{}\".format(hashtag_id, hashtag,tweet['id']), file=f)\n",
    "                    no_conflict = False\n",
    "        if no_conflict:\n",
    "            tweets_filtered.append(tweet)\n",
    "    \n",
    "    if len(tweets_filtered) == 0:\n",
    "        # Means all the fetched tweets are unfiltered as of conflict\n",
    "        print(\"No tweets to write database\")\n",
    "        \n",
    "        last_tweet = tweets[len(tweets)-1]\n",
    "        max_id = last_tweet['id'] - 1\n",
    "    \n",
    "    else:\n",
    "        print(\"{} tweets written to db\".format(len(tweets_filtered)))\n",
    "        try:\n",
    "            tweets_db.insert_many([reshape_tweet(tweet, hashtag_id) for tweet in tweets_filtered])\n",
    "        except BulkWriteError as bwe:\n",
    "            pprint(bwe.details)\n",
    "            raise\n",
    "\n",
    "        last_tweet = tweets_filtered[len(tweets_filtered)-1]\n",
    "        max_id = last_tweet['id'] - 1\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://twitter.com/sercanoksak/status/1246154630175875076"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
