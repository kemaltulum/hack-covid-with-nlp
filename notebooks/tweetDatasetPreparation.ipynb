{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import BulkWriteError\n",
    "from gensim.models import KeyedVectors\n",
    "import re, pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "\n",
    "db = client.covid_hack\n",
    "tweets_db = db.tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_tweet_text(tweet_text):\n",
    "    tweet_text = re.sub(r'http\\S+', '', tweet_text)\n",
    "    tweet_text = re.sub(r'#\\S+', '', tweet_text)\n",
    "    tweet_text = re.sub(r'@\\S+', '', tweet_text)\n",
    "    tweet_text = re.sub(r'[^\\w\\s]',' ',tweet_text)\n",
    "    return tweet_text\n",
    "\n",
    "def lower_tr(text):\n",
    "    lowerMap = {ord(u'A'): u'a',ord(u'A'): u'a',ord(u'B'): u'b',ord(u'C'): u'c',ord(u'Ç'): u'ç',ord(u'D'): u'd',ord(u'E'): u'e',ord(u'F'): u'f',ord(u'G'): u'g',ord(u'Ğ'): u'ğ',ord(u'H'): u'h',ord(u'I'): u'ı',ord(u'İ'): u'i',ord(u'J'): u'j',ord(u'K'): u'k',ord(u'L'): u'l',ord(u'M'): u'm',ord(u'N'): u'n',ord(u'O'): u'o',ord(u'Ö'): u'ö',ord(u'P'): u'p',ord(u'R'): u'r',ord(u'S'): u's',ord(u'Ş'): u'ş',ord(u'T'): u't',ord(u'U'): u'u',ord(u'Ü'): u'ü',ord(u'V'): u'v',ord(u'Y'): u'y',ord(u'Z'): u'z',ord(u'W'): u'w',ord(u'Q'): u'q',ord(u'X'): u'x'}\n",
    "    text = text.translate(lowerMap)\n",
    "    return text\n",
    "\n",
    "stop_words = []\n",
    "with open('stop_words') as f:\n",
    "    stop_words = f.read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 0\n"
     ]
    }
   ],
   "source": [
    "tweet_data_all = []\n",
    "error_counter = 0\n",
    "\n",
    "for tweet in tweets_db.find():\n",
    "    if tweet[\"full_text\"].startswith('RT'):\n",
    "        continue\n",
    "    try:\n",
    "        tweet_data = {}\n",
    "        tweet_data['id'] = tweet['id']\n",
    "        tweet_data['created_at'] = tweet['created_at']\n",
    "        tweet_data['hashtag_id'] = tweet['hashtag_id']\n",
    "        tweet_data['full_text'] = tweet['full_text']\n",
    "        tweet_data['retweet_count'] = tweet['retweet_count']\n",
    "        tweet_data['favorite_count'] = tweet['favorite_count']\n",
    "        tweet_data['user_follower_count'] = tweet['user']['followers_count']\n",
    "        tweet_data['lemmatized_text'] = clear_tweet_text(tweet['zemberek_nlp']['lemmatized_text'])\n",
    "        tweet_data['tokenized_text'] = clear_tweet_text(tweet['zemberek_nlp']['tokenized_text'])\n",
    "        tweet_data['num_of_hashtags'] = len(tweet['entities']['hashtags'])\n",
    "        tweet_data['num_of_mentions'] = len(tweet['entities']['user_mentions'])\n",
    "        tweet_data['num_of_urls'] = len(tweet['entities']['urls'])\n",
    "        \n",
    "        processed_text_arr = []\n",
    "        for word in tweet_data[\"lemmatized_text\"].split():\n",
    "            if word not in stop_words:\n",
    "                processed_text_arr.append(word)\n",
    "        \n",
    "        processed_text = \" \".join(processed_text_arr)\n",
    "        tweet_data['processed_text'] = processed_text\n",
    "        \n",
    "        if len(tweet_data['processed_text'].split()) <= 3:\n",
    "            continue\n",
    "        tweet_data_all.append(tweet_data)\n",
    "    except KeyError as e: \n",
    "        print(\"Error on tweet: {}\".format(tweet[\"full_text\"]))\n",
    "        error_counter += 1\n",
    "\n",
    "print(\"Error: {}\".format(error_counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fields To Add DataFrame\n",
    "* id\n",
    "* created_at\n",
    "* hashtag_id\n",
    "* full_text\n",
    "* user.followers_count\n",
    "* zemberek_nlp.lemmatized_text\n",
    "* zemberek_nlp.tokenized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.DataFrame(tweet_data_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>hashtag_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_follower_count</th>\n",
       "      <th>lemmatized_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>num_of_hashtags</th>\n",
       "      <th>num_of_mentions</th>\n",
       "      <th>num_of_urls</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1247616672481062913</td>\n",
       "      <td>Tue Apr 07 20:06:08 +0000 2020</td>\n",
       "      <td>#şüpheduymuyorum</td>\n",
       "      <td>@fatihportakal hemen hemen hergün 70’li sayıla...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276</td>\n",
       "      <td>hemen hemen hergün 70 sayı vermek ölmek için b...</td>\n",
       "      <td>hemen hemen hergün 70 li sayılar veriliyor öl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hemen hemen hergün 70 sayı vermek ölmek tesadü...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1247466322512031744</td>\n",
       "      <td>Tue Apr 07 10:08:42 +0000 2020</td>\n",
       "      <td>#şüpheduymuyorum</td>\n",
       "      <td>@fatihportakal Senin bi amerikan ciciş köpüşü ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>sen bir Amerikan cici kopmak olmak artık  hanım</td>\n",
       "      <td>senin bir amerikan cici kopuşu oluşundan artı...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Amerikan cici kopmak hanım</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1247435972490473472</td>\n",
       "      <td>Tue Apr 07 08:08:06 +0000 2020</td>\n",
       "      <td>#şüpheduymuyorum</td>\n",
       "      <td>#DünyaSağlıkGünü #şüpheduymuyorum #kitlervarla...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>tanımak ve tedavi temel belirlemek unsur çok b...</td>\n",
       "      <td>tanı ve tedavide temel belirleyici unsuru ç...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>tanımak tedavi temel belirlemek unsur büyük or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1247276012964130816</td>\n",
       "      <td>Mon Apr 06 21:32:29 +0000 2020</td>\n",
       "      <td>#şüpheduymuyorum</td>\n",
       "      <td>@fatihportakal Biri Baban Diğeri Deden Olan Sö...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>527</td>\n",
       "      <td>biri baba diğer de olmak söz dünya dev Amerika...</td>\n",
       "      <td>biri baban diğeri deden olan sözde dünya devl...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>baba söz dünya dev Amerika Avrupa dolar euro k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1247182225466146816</td>\n",
       "      <td>Mon Apr 06 15:19:48 +0000 2020</td>\n",
       "      <td>#şüpheduymuyorum</td>\n",
       "      <td>Denklik bekleyen Türk Hekimleri olarak ben ve ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>denklik beklemek Türk hekim olmak ben ve yüz a...</td>\n",
       "      <td>denklik bekleyen türk hekimleri olarak ben ve ...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>denklik beklemek Türk hekim arkadaş saha görev...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                      created_at        hashtag_id  \\\n",
       "0  1247616672481062913  Tue Apr 07 20:06:08 +0000 2020  #şüpheduymuyorum   \n",
       "1  1247466322512031744  Tue Apr 07 10:08:42 +0000 2020  #şüpheduymuyorum   \n",
       "2  1247435972490473472  Tue Apr 07 08:08:06 +0000 2020  #şüpheduymuyorum   \n",
       "3  1247276012964130816  Mon Apr 06 21:32:29 +0000 2020  #şüpheduymuyorum   \n",
       "4  1247182225466146816  Mon Apr 06 15:19:48 +0000 2020  #şüpheduymuyorum   \n",
       "\n",
       "                                           full_text  retweet_count  \\\n",
       "0  @fatihportakal hemen hemen hergün 70’li sayıla...              0   \n",
       "1  @fatihportakal Senin bi amerikan ciciş köpüşü ...              0   \n",
       "2  #DünyaSağlıkGünü #şüpheduymuyorum #kitlervarla...              1   \n",
       "3  @fatihportakal Biri Baban Diğeri Deden Olan Sö...              0   \n",
       "4  Denklik bekleyen Türk Hekimleri olarak ben ve ...              0   \n",
       "\n",
       "   favorite_count  user_follower_count  \\\n",
       "0               0                  276   \n",
       "1               1                   63   \n",
       "2               2                  122   \n",
       "3               0                  527   \n",
       "4               0                   18   \n",
       "\n",
       "                                     lemmatized_text  \\\n",
       "0  hemen hemen hergün 70 sayı vermek ölmek için b...   \n",
       "1  sen bir Amerikan cici kopmak olmak artık  hanım     \n",
       "2  tanımak ve tedavi temel belirlemek unsur çok b...   \n",
       "3  biri baba diğer de olmak söz dünya dev Amerika...   \n",
       "4  denklik beklemek Türk hekim olmak ben ve yüz a...   \n",
       "\n",
       "                                      tokenized_text  num_of_hashtags  \\\n",
       "0   hemen hemen hergün 70 li sayılar veriliyor öl...                1   \n",
       "1   senin bir amerikan cici kopuşu oluşundan artı...                1   \n",
       "2     tanı ve tedavide temel belirleyici unsuru ç...                3   \n",
       "3   biri baban diğeri deden olan sözde dünya devl...                1   \n",
       "4  denklik bekleyen türk hekimleri olarak ben ve ...                2   \n",
       "\n",
       "   num_of_mentions  num_of_urls  \\\n",
       "0                1            0   \n",
       "1                2            0   \n",
       "2                0            0   \n",
       "3                1            0   \n",
       "4                6            0   \n",
       "\n",
       "                                      processed_text  \n",
       "0  hemen hemen hergün 70 sayı vermek ölmek tesadü...  \n",
       "1                         Amerikan cici kopmak hanım  \n",
       "2  tanımak tedavi temel belirlemek unsur büyük or...  \n",
       "3  baba söz dünya dev Amerika Avrupa dolar euro k...  \n",
       "4  denklik beklemek Türk hekim arkadaş saha görev...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = tweet_df[tweet_df['hashtag_id'] != '#gerçekfikrine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>user_follower_count</th>\n",
       "      <th>num_of_hashtags</th>\n",
       "      <th>num_of_mentions</th>\n",
       "      <th>num_of_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.541600e+04</td>\n",
       "      <td>45416.000000</td>\n",
       "      <td>45416.000000</td>\n",
       "      <td>4.541600e+04</td>\n",
       "      <td>45416.000000</td>\n",
       "      <td>45416.000000</td>\n",
       "      <td>45416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.247185e+18</td>\n",
       "      <td>2.860996</td>\n",
       "      <td>9.005351</td>\n",
       "      <td>2.164938e+03</td>\n",
       "      <td>1.772745</td>\n",
       "      <td>0.637198</td>\n",
       "      <td>0.050731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.553223e+14</td>\n",
       "      <td>35.398020</td>\n",
       "      <td>151.392778</td>\n",
       "      <td>2.745303e+04</td>\n",
       "      <td>1.704709</td>\n",
       "      <td>1.387295</td>\n",
       "      <td>0.222934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.245388e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.246115e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.247558e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.400000e+01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.247934e+18</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.980000e+02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.249804e+18</td>\n",
       "      <td>2264.000000</td>\n",
       "      <td>18861.000000</td>\n",
       "      <td>1.410066e+06</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  retweet_count  favorite_count  user_follower_count  \\\n",
       "count  4.541600e+04   45416.000000    45416.000000         4.541600e+04   \n",
       "mean   1.247185e+18       2.860996        9.005351         2.164938e+03   \n",
       "std    9.553223e+14      35.398020      151.392778         2.745303e+04   \n",
       "min    1.245388e+18       0.000000        0.000000         0.000000e+00   \n",
       "25%    1.246115e+18       0.000000        0.000000         9.000000e+00   \n",
       "50%    1.247558e+18       0.000000        1.000000         6.400000e+01   \n",
       "75%    1.247934e+18       0.000000        2.000000         2.980000e+02   \n",
       "max    1.249804e+18    2264.000000    18861.000000         1.410066e+06   \n",
       "\n",
       "       num_of_hashtags  num_of_mentions   num_of_urls  \n",
       "count     45416.000000     45416.000000  45416.000000  \n",
       "mean          1.772745         0.637198      0.050731  \n",
       "std           1.704709         1.387295      0.222934  \n",
       "min           0.000000         0.000000      0.000000  \n",
       "25%           1.000000         0.000000      0.000000  \n",
       "50%           1.000000         0.000000      0.000000  \n",
       "75%           2.000000         1.000000      0.000000  \n",
       "max          29.000000        28.000000      3.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.to_csv('tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('tweet_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = KeyedVectors.load_word2vec_format('/home/kemal/Desktop/Workspace/Turkish-Word2Vec/trmodel_me', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_vectors_all = []\n",
    "for ii in range(0, len(tweet_df)):\n",
    "    hashtag_id = tweet_df.iloc[ii]['hashtag_id']\n",
    "    if hashtag_id != '#neyinnesi':\n",
    "        continue\n",
    "    processed_text = tweet_df.iloc[ii]['processed_text']\n",
    "    \n",
    "    tweet_vectors = []\n",
    "    for word in processed_text.split():\n",
    "        if word in word_vectors:\n",
    "            tweet_vectors.append(word_vectors.get_vector(word))\n",
    "    tweet_vectors_all.append(tweet_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_vecs', \"wb\") as f:\n",
    "    pickle.dump(tweet_vectors_all, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
